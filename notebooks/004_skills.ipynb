{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WM7RBW2MDY"
   },
   "source": [
    "# Parameterizing Skills with the Solution Building Library\n",
    "\n",
    "This example notebook demonstrates how to instantiate and parameterize skills with the Intrinsic Solution Building Library.\n",
    "\n",
    "We pay special attention on how to do this in practice with the tools provided by Jupyter in VS Code.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Important**\n",
    "\n",
    "This notebook requires a running Flowstate solution to connect to. To start a solution:\n",
    "\n",
    "1. Navigate to [portal.intrinsic.ai](https://portal.intrinsic.ai/) and sign in\n",
    "   using your registered Flowstate account.\n",
    "\n",
    "1. Do **one** of the following:\n",
    "    - Create a new solution:\n",
    "        1. Click \"Create new solution\" and choose \"From an example\".\n",
    "        1. Select `building_block:building_block_module2`\n",
    "        1. Click \"Create\".\n",
    "    - Or open an existing solution that was created from the `building_block:building_block_module2` example:\n",
    "        1. Hover over the solution in the list.\n",
    "        1. Click \"Open solution\" or \"Start solution\".\n",
    "\n",
    "1. Recommended: Keep the browser tab with the Flowstate solution editor open to watch the effect of notebook actions such as running a skill. You can simultaneously interact with the solution through the web UI and the notebook.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IC17Y1UO34"
   },
   "source": [
    "## Connect to solution\n",
    "\n",
    "Let's start with the typical preamble:\n",
    "\n",
    "- Import the relevant modules.\n",
    "- Connect to the deployed solution.\n",
    "- Define some shortcut variables for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "3QKOISP0XS"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from intrinsic.math.python import data_types\n",
    "from intrinsic.solutions import deployments\n",
    "from intrinsic.solutions import behavior_tree as bt\n",
    "\n",
    "solution = deployments.connect_to_selected_solution()\n",
    "\n",
    "executive = solution.executive\n",
    "resources = solution.resources\n",
    "skills = solution.skills\n",
    "world = solution.world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTGLJTH70G"
   },
   "source": [
    "Create an additional frame in the belief world that will be used by some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "DPQLQRVT4S"
   },
   "outputs": [],
   "source": [
    "if 'pregrasp' not in world.building_block0.frame_names:\n",
    "    world.create_frame(\n",
    "        'pregrasp',\n",
    "        world.building_block0,\n",
    "        data_types.Pose3(\n",
    "            rotation=data_types.Rotation3.from_euler_angles(rpy_degrees=[180, 0, 90]),\n",
    "            translation=[0,0,0.05]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FE90MLHVI"
   },
   "source": [
    "At this point we recommend saving the solution in the Flowstate solution editor UI so that the created frame will persist across world resets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EA5GCIXMN"
   },
   "source": [
    "## Creating your first skill instance\n",
    "\n",
    "We use the `enable_gripper` skill as an example for creating our very first skill instance step-by-step.\n",
    "\n",
    "If you haven't done so yet, try to find the skill via auto-completion. I.e., type `skills.` and press <kbd>Ctrl</kbd> + <kbd>Space</kbd> if the dropdown with suggestions does not show up automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "JCJ74B66G4"
   },
   "outputs": [],
   "source": [
    "# Type `skills.` and choose `enable_gripper`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUC24SI2BI"
   },
   "source": [
    "Alternatively, you can also list the available skills in the solution with `dir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "335N0D41TE"
   },
   "outputs": [],
   "source": [
    "dir(skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBV4IDPGIR"
   },
   "source": [
    "The printed list should contain `enable_gripper`, indicating that `skills.enable_gripper` exists. `skills.enable_gripper` is a Python class that helps you to instantiate the skill with the appropriate parameters. The class gets dynamically generated by the Solution Building Library so that it exactly matches the skills version that is currently installed in your solution.\n",
    "\n",
    "You get information about a skill helper class by using Python's `help()` method. It'll print information about the class, including the signature of its init method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "JDWZR8NAYJ"
   },
   "outputs": [],
   "source": [
    "help(skills.enable_gripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCGOW8LBJ4"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Tip**\n",
    "\n",
    "An alternative to calling the `help()` function manually in a notebook cell is to use the **Jupyter PowerToys** extension:\n",
    "\n",
    "1. Click on the **Jupyter** icon <img src=\"https://raw.githubusercontent.com/microsoft/vscode-codicons/6ceb091d5c40da3e5836e3d80b08d3f74efc4cbf/src/icons/notebook.svg\" width=\"25\"> in the activity bar (to the far left side of the VS Code window).\n",
    "1. Place your cursor, e.g., on `skills.enable_gripper` in the cell below or select any other code in a code cell.\n",
    "1. See the `help` output shown live under **CONTEXTUAL HELP** in the sidebar (to the left side of the VS Code window).\n",
    "\n",
    "You can also check out the [live animation of the contextual help feature](https://github.com/microsoft/vscode-jupyter-powertoys?tab=readme-ov-file#contextual-help) on the Jupyter PowerToys website.\n",
    "\n",
    "</div>\n",
    "\n",
    "The help output will show you what parameters the skill expects. In the case of the `enable_gripper` skill the printed signature is:\n",
    "\n",
    "```\n",
    "Skill_enable_gripper(\n",
    "    *,\n",
    "    clear_faults: bool,\n",
    "    gripper: intrinsic.solutions.providers.ResourceHandle = ResourceHandle.create(...))\n",
    ")\n",
    "```\n",
    "\n",
    "This means the only required parameter is a boolean and you can instantiate the skill as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "WSJD01FMJI"
   },
   "outputs": [],
   "source": [
    "enable_gripper_skill = skills.enable_gripper(clear_faults=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVLDQMFPN5"
   },
   "source": [
    "Note that for inclusion in a behavior tree, you would typically wrap the skill instance in a task node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "YPX3A1NY01"
   },
   "outputs": [],
   "source": [
    "enable_gripper = bt.Task(action=enable_gripper_skill, name='Enable gripper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKD2PNJKI0"
   },
   "source": [
    "The skill also has a second parameter called `gripper` which is of `type intrinsic.solutions.providers.ResourceHandle`. It specifies which gripper in the solution to enable. In this simple case we don't have to explicitly specify this resource parameter because there is only one gripper resource in the solution. In other cases we have to specify resources explicitly which is detailed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6QQ06L3EQ"
   },
   "source": [
    "## Resources\n",
    "\n",
    "`solution.Resources` is a lightweight wrapper that allows access to all the resource information that has been configured when authoring the solution. Resources can be passed to skills as a special type of parameter, e.g., when we want to specify which robot to move or which camera to use. You can get a list containing the names of all registered resources:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "OF9A1NVR8K"
   },
   "outputs": [],
   "source": [
    "dir(resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKO8OIMD77"
   },
   "source": [
    "\n",
    "Each resource consists of a name and a list of capabilities. When providing a resource as a parameter to a skill, the skill's required capabilities get checked against this list of capabilities. A resource is considered compatible if the skill's required capabilities are a subset of the provided capabilities.\n",
    "\n",
    "For example, in the building block solution a gripper resource with the name `picobot_gripper` is present.\n",
    "If you print it, you can see the corresponding resource handle which is defined by its name `picobot_gripper` and its list of capabilities (=`types`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "W9Q1XE1YGV"
   },
   "outputs": [],
   "source": [
    "resources.picobot_gripper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMH0B4SS7F"
   },
   "source": [
    "You can also check which resources are compatible with a particular skill. E.g., you can list the resources which can be passed to the `gripper` parameter of the `enable_gripper` skill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "03RXJN3C2C"
   },
   "outputs": [],
   "source": [
    "dir(skills.enable_gripper.compatible_resources.gripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JJIM6XAQQ"
   },
   "source": [
    "This means you can use `resources.picobot_gripper` for the `gripper` parameter of the `enable_gripper` skill. If there is only one resource in a solution that matches a skills requirements then the Solution Building Library will automatically determine a default parameter for the skill. This is why, in our simple solution, the `enable_gripper` skill can be instantiated equivalently in the following two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "ZDH1KLSJVN"
   },
   "outputs": [],
   "source": [
    "# Use default gripper (only possible if there is only one compatible gripper in the solution).\n",
    "enable_gripper_skill = skills.enable_gripper(clear_faults=True)\n",
    "\n",
    "# Explicitly specify which gripper to use.\n",
    "enable_gripper_skill = skills.enable_gripper(\n",
    "        clear_faults=True,\n",
    "        gripper=resources.picobot_gripper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUQ2GJTNZZ"
   },
   "source": [
    "## Nested skill parameters\n",
    "\n",
    "The suction gripper in the building blocks solution can be controlled with the `control_suction_gripper` skill. Through `help(skills.control_suction_gripper)` you can get the skills signature:\n",
    "\n",
    "```\n",
    "Skill_control_suction_gripper(\n",
    "    *,\n",
    "    grasp: intrinsic.solutions.skills.control_suction_gripper.GraspRequest,\n",
    "    release: intrinsic.solutions.skills.control_suction_gripper.ReleaseRequest,\n",
    "    blow_off: intrinsic.solutions.skills.control_suction_gripper.BlowOffRequest,\n",
    "    suction_gripper: intrinsic.solutions.providers.ResourceHandle = ResourceHandle.create(...))\n",
    ")\n",
    "```\n",
    "\n",
    "You can see that the skill requires the three parameters `grasp`, `release` and `blow_off` with the types `intrinsic.solutions.skills.control_suction_gripper.GraspRequest/ReleaseRequest/BlowOffRequest`. Generally, skill parameters are defined by skill authors as [Protocol Buffer (proto)](https://protobuf.dev/) messages and the signature of a skill's helper class in Python is derived from the skill's parameter proto. The skill's parameter proto can contain [nested messages](https://protobuf.dev/programming-guides/proto3/#nested) in which case the Solution Building Library will automatically create helper classes for each type of nested message. In the case of `control_suction_gripper`, the following helper classes are generated:\n",
    "\n",
    "- `skills.control_suction_gripper.GraspRequest`\n",
    "- `skills.control_suction_gripper.ReleaseRequest`\n",
    "- `skills.control_suction_gripper.BlowOffRequest`\n",
    "\n",
    "Again, you can inspect these helper classes using `help()`, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "GBZH1YW70P"
   },
   "outputs": [],
   "source": [
    "help(skills.control_suction_gripper.GraspRequest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OX5158Q7VW"
   },
   "source": [
    "All of these three helper classes (currently) take no parameters. That means, based on the skills Python signature, you'd expect that the following works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "GICKKG1RFD"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Will raise an exception!\n",
    "    skills.control_suction_gripper(\n",
    "        grasp=skills.control_suction_gripper.GraspRequest(),\n",
    "        release=skills.control_suction_gripper.ReleaseRequest(),\n",
    "        blow_off=skills.control_suction_gripper.BlowOffRequest())\n",
    "except Exception as e:\n",
    "    # Print error message but do not fail the cell.\n",
    "    print(repr(e))\n",
    "    print(repr(e.__cause__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X249I9BB94"
   },
   "source": [
    "However, the above will raise an exception that the parameters `grasp` and `release` cannot be passed at the same time. The Solution Building Library cannot map all protobuf features to Python perfectly. In this case, the skill's parameter proto contains a [oneof](https://protobuf.dev/programming-guides/proto3/#oneof) definition which cannot be indicated by the skills Python signature. Instead you get the observed runtime error.\n",
    "\n",
    "The solution here is to only pass one of {`grasp`, `release` and `blow_off`} at a time which makes sense because we either want to \"grasp\", to \"release\" or to \"blow off\". Having this in mind, we can, e.g., create two working instances of the `control_suction_gripper` skill, one for grasping and one for releasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "U6TC8IYAL2"
   },
   "outputs": [],
   "source": [
    "grasp = skills.control_suction_gripper(\n",
    "    grasp=skills.control_suction_gripper.GraspRequest())\n",
    "\n",
    "release = skills.control_suction_gripper(\n",
    "    release=skills.control_suction_gripper.ReleaseRequest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3J2FQOSQ30"
   },
   "source": [
    "## Motion skills\n",
    "\n",
    "Various common robot motions can all be expressed and executed with a single skill: the `move_robot` skill. In this section we'll demonstrate how to use this skill.\n",
    "\n",
    "### Motion targets\n",
    "\n",
    "Motion targets can be defined in terms of Cartesian constraints or a robot joint configuration. The two most common motion target definitions are the Cartesian `PoseEquality` constraint and the `JointConfiguration`.\n",
    "\n",
    "A `JointConfiguration` is a list of joint angles and can be obtained in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "MTV0O9Z394"
   },
   "outputs": [],
   "source": [
    "# Joint configuration from plain values\n",
    "joint_target_free = skills.move_robot.JointVec(\n",
    "    joints=[\n",
    "        math.radians(-90),\n",
    "        math.radians(-90),\n",
    "        math.radians(-90),\n",
    "        math.radians(-90),\n",
    "        math.radians(90),\n",
    "        math.radians(90)])\n",
    "\n",
    "# Named joint configuration stored in the world\n",
    "joint_target_global_config = world.robot.joint_configurations.view_pose_left\n",
    "\n",
    "# Joint configuration from the current robot position in the belief world,\n",
    "# useful, e.g., after jogging the robot in the frontend\n",
    "joint_target_world = skills.move_robot.JointVec(joints=world.robot.joint_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E030UNP80E"
   },
   "source": [
    "These joint configurations can be used to create a `move_robot` skill instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "XDCXTUQVQ2"
   },
   "outputs": [],
   "source": [
    "# Disable collision checking.\n",
    "collisions_disabled = skills.move_robot.CollisionSettings(disable_collision_checking=True)\n",
    "\n",
    "# Define the single motion target as joint configuration in a motion_segment and\n",
    "# disable collision checking for this segment.\n",
    "move_home_unsafe = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(\n",
    "            joint_position=joint_target_free,\n",
    "            collision_settings=collisions_disabled)])\n",
    "\n",
    "executive.run(move_home_unsafe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9MP6HGFFM"
   },
   "source": [
    "Next to `JointMotionTarget`s there are also Cartesian motion target constraints. The most common constraint used to define a motion target is `PoseEquality` which defines the Cartesian pose of a frame attached to the robot (i.e., the moving frame). Besides the moving frame a target frame needs to be defined that defines the target pose of the moving frame.\n",
    "Optionally, you can define an `target_frame_offset` between these two frames. The target offset defines the target position of the moving frame relative to the target frame.\n",
    "\n",
    "To create a `PoseEquality` constraint which aligns the gripper tool frame with the pregrasp frame above the building block use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "TSDM7NULJL"
   },
   "outputs": [],
   "source": [
    "block_pregrasp = skills.move_robot.PoseEquality(\n",
    "    moving_frame=world.picobot_gripper.tool_frame,\n",
    "    target_frame=world.building_block0.pregrasp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6244N9MTZ5"
   },
   "source": [
    "The motion can then get generated by creating a segment with a single cartesian motion target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "MQ7O0LJ59E"
   },
   "outputs": [],
   "source": [
    "move = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(cartesian_pose=block_pregrasp)])\n",
    "\n",
    "executive.run(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VHU9ZTG6I"
   },
   "source": [
    "The `PoseEquality` constraint also gives you the ability to configure an offset between the moving frame and the target frame.\n",
    "This will move to 9cm above the center of the building block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "8M4Z6MU22F"
   },
   "outputs": [],
   "source": [
    "above_block = skills.move_robot.PoseEquality(\n",
    "    moving_frame=world.picobot_gripper.tool_frame,\n",
    "    target_frame=world.building_block0,\n",
    "    target_frame_offset=data_types.Pose3(\n",
    "        rotation=data_types.Rotation3.from_euler_angles(rpy_degrees=[180, 0, 90]),\n",
    "        translation=[0,0,0.09]))\n",
    "\n",
    "move = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(cartesian_pose=above_block)])\n",
    "\n",
    "executive.run(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J86GSHJGD9"
   },
   "source": [
    "To define a Cartesian motion relative to the current pose of a moving frame, set target frame equal to moving frame and define the relative motion using the target offset.\n",
    "The following moton request will move the tool frame 9 cm in negative z-direction of the gripper tool frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "3WTCT8OLWT"
   },
   "outputs": [],
   "source": [
    "offset = data_types.Pose3(translation=[0,0,-0.09])\n",
    "relative_pose = skills.move_robot.PoseEquality(\n",
    "                        moving_frame=world.picobot_gripper.tool_frame,\n",
    "                        target_frame=world.picobot_gripper.tool_frame,\n",
    "                        target_frame_offset=offset)\n",
    "\n",
    "move = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(cartesian_pose=relative_pose)])\n",
    "\n",
    "executive.run(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NM60MOLBCI"
   },
   "source": [
    "### Linear Cartesian Motions\n",
    "\n",
    "The previous motions find a (collision free) motion in joint configuration space and executes it. To plan and execute a Cartesian linear motion you can define a `linear_move` path constraint. The following motion moves down by 5 cm in z direction linear in Cartesian space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "RJD6A1RD49"
   },
   "outputs": [],
   "source": [
    "offset = data_types.Pose3(translation=[0,0,0.05])\n",
    "relative_pose = skills.move_robot.PoseEquality(\n",
    "                        moving_frame=world.picobot_gripper.tool_frame,\n",
    "                        target_frame=world.picobot_gripper.tool_frame,\n",
    "                        target_frame_offset=offset)\n",
    "\n",
    "# Motion definition with single segment that defines a linear move to an orientation\n",
    "move_down_linear = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(\n",
    "            cartesian_pose=relative_pose,\n",
    "            motion_type=skills.move_robot.MotionSegment.LINEAR)])\n",
    "\n",
    "# Move robot to home pose first, then move to pregrasp\n",
    "executive.run([move_home_unsafe, move_down_linear])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNRB014YG1"
   },
   "source": [
    "### Collision Settings\n",
    "In the previous examples you have seen that sometimes the motion disables collision checking and sometimes collision checking is not set. By default, motion planning enables collision checking with the environment and attempts to find a collision free path to the motion target. If you want to disable collision checking you need to disable it for the respective motion segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "UGZ8O1IC57"
   },
   "outputs": [],
   "source": [
    "move_unsafe = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(\n",
    "            joint_position=joint_target_global_config,\n",
    "            collision_settings=collisions_disabled)])\n",
    "\n",
    "executive.run(move_unsafe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7QWCEDZQO"
   },
   "source": [
    "If collision settings is not set, a collision free trajectory is generated. By default, collision free means that no geometries are intersecting. While this is sufficient in theory when dealing with uncertainties in the environment it is recommended to set a minimum margin. The minimum margin enforces that the required motion has at least the distance defined in the margin to be considered collision free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "8OHSFYN5LH"
   },
   "outputs": [],
   "source": [
    "# Define a collision margin of 1 cm\n",
    "collision_margin = skills.move_robot.CollisionSettings(minimum_margin=0.01)\n",
    "\n",
    "# Define a motion with one segment and a collision margin of 1 cm.\n",
    "move_with_margin = skills.move_robot(\n",
    "    motion_segments=[\n",
    "        skills.move_robot.MotionSegment(\n",
    "            joint_position=joint_target_free,\n",
    "            collision_settings=collision_margin)])\n",
    "\n",
    "executive.run(move_with_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XWVRSB5UE"
   },
   "source": [
    "More complex collision settings can be designed using `CollisionRules`. `CollisionRules` allow to set object specific exclusion pairs and margins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01E6LH9U3I"
   },
   "source": [
    "### More complex motions: Multi segment moves\n",
    "\n",
    "To achieve more complex behavior, motion segments can be combined together to one motion by defining multi-segment moves.\n",
    "\n",
    "The following move requests contains two motion segments. The first segments defines the motion that aligns the gripper tool frame with the pregrasp pose of the building block. The second motion segment defines the final target 10 cm in x direction relative to the pregrasp pose.\n",
    "\n",
    "Note: When defining multi-segment motions, the robot will not stop at the waypoint. The robot will only come to an halt at the target of the final motion segment. The resulting motion will not pass through the exact waypoint. Instead, it passes the waypoints with a user configurable tightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "WD9MKKRHY8"
   },
   "outputs": [],
   "source": [
    "# Define planned move segment 1: Move to 15cm in -z-direction of pregrasp position\n",
    "z_offset = -0.15\n",
    "modified_pregrasp_position = skills.move_robot.PositionEquality(\n",
    "    moving_frame=world.picobot_gripper.tool_frame,\n",
    "    target_frame=world.building_block0.pregrasp,\n",
    "    target_frame_offset=skills.move_robot.Point(z=z_offset))\n",
    "motion_segment1 = skills.move_robot.MotionSegment(position_equality=modified_pregrasp_position)\n",
    "\n",
    "# Define joint move segment 2: Move 10 cm in x-direction of the modified pregrasp. This is the final motion target.\n",
    "relative_move_position = skills.move_robot.PositionEquality(\n",
    "    moving_frame=world.picobot_gripper.tool_frame,\n",
    "    target_frame=world.building_block0.pregrasp,\n",
    "    target_frame_offset=skills.move_robot.Point(x=0.1, z=z_offset))\n",
    "motion_segment2 = skills.move_robot.MotionSegment(position_equality=relative_move_position)\n",
    "\n",
    "# Define a blending parameter that ensures that we pass through the pregrasp position (motion target segment 1)\n",
    "# with an accuracy of 0.01 rad in joint configuration space\n",
    "blending_parameter = skills.move_robot.BlendingParameters(\n",
    "    joint_blending=skills.move_robot.JointBlendingParameters(\n",
    "        desired_tightness_rad=0.01))\n",
    "\n",
    "# Define move_robot skill that moves the end-effector to a 10 cm offset location (x-axis block) moving through the pregrasp position.\n",
    "multi_segment_move = skills.move_robot(\n",
    "    motion_segments=[motion_segment1, motion_segment2],\n",
    "    curve_parameters=blending_parameter)\n",
    "\n",
    "executive.run(multi_segment_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9QE2CRN1S"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Take a look at the following example notebooks to learn:\n",
    "\n",
    "- How to create behavior trees with control flow nodes such as [sequences](005_sequence.ipynb), [loops and branches](006_loop_and_branch.ipynb) or [retries](007_retry.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
