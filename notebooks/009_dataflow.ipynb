{
  "cells": [
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "X4E5K738U0",
      "cell_type": "markdown",
      "source": [
        "# Dataflow using skill return values and parameters\n",
        "\n",
        "This example notebook demonstrates moving over a couple of objects:\n",
        "\n",
        "- Use `estimate_pose` skill to detect objects\n",
        "- Pass information retrieved as return value from one skill as a parameter to another skill\n",
        "\n",
        "In particular, this example covers:\n",
        "\n",
        "- Behavior tree features\n",
        "    - Skill return values\n",
        "    - Passing data to a skill using a blackboard value for parameters\n",
        "    - Use the loop counter of a `Loop` node\n",
        "    - Write a custom condition expression\n",
        "\n",
        "\u003cdiv class=\"alert alert-info\"\u003e\n",
        "\n",
        "**Important**\n",
        "\n",
        "This notebook requires a running Flowstate solution to connect to. To start a solution:\n",
        "\n",
        "1. Navigate to [flowstate.intrinsic.ai](https://flowstate.intrinsic.ai/) and sign in\n",
        "   using your registered Flowstate account.\n",
        "\n",
        "1. Do **one** of the following:\n",
        "    - Create a new solution:\n",
        "        1. Click \"Create new solution\" and choose \"From an example\".\n",
        "        1. Select `pick_and_place:pick_and_place_module2`\n",
        "        1. Click \"Create\".\n",
        "    - Or open an existing solution that was created from the `pick_and_place:pick_and_place_module2` example:\n",
        "        1. Hover over the solution in the list.\n",
        "        1. Click \"Open solution\" or \"Start solution\".\n",
        "\n",
        "1. Recommended: Keep the browser tab with the Flowstate solution editor open to watch the effect of notebook actions such as running a skill. You can simultaneously interact with the solution through the web UI and the notebook.\n",
        "\n",
        "\u003c/div\u003e"
      ]
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "L6VR4NF89Z",
      "cell_type": "markdown",
      "source": [
        "First, connect to your solution and define convenience shortcuts:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "KRGUJ850IU",
      "cell_type": "code",
      "source": [
        "from intrinsic.math.python import data_types\n",
        "from intrinsic.solutions import behavior_tree as bt\n",
        "from intrinsic.solutions import deployments\n",
        "from intrinsic.solutions import worlds\n",
        "\n",
        "solution = deployments.connect_to_selected_solution()\n",
        "\n",
        "executive = solution.executive\n",
        "world = solution.world\n",
        "skills = solution.skills\n",
        "resources = solution.resources\n",
        "\n",
        "move_robot = skills.ai.intrinsic.move_robot\n",
        "estimate_pose = skills.ai.intrinsic.estimate_pose"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "colab_type": "text"
      },
      "id": "CL12IAPCH8",
      "cell_type": "markdown",
      "source": [
        "# Create the Behavior Tree"
      ]
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "SNYM4FXBFT",
      "cell_type": "markdown",
      "source": [
        "First, define most of the necessary skills. The overall flow is to move to a home position, then identify blocks in the workcell, and then move to the first one seen."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "OODWTC3ZWI",
      "cell_type": "code",
      "source": [
        "move_home = bt.Task(\n",
        "    name=\"Move to Home\",\n",
        "    action=move_robot(\n",
        "        motion_segments=[\n",
        "            move_robot.intrinsic_proto.skills.MotionSegment(\n",
        "                joint_position=world.robot.joint_configurations.home,\n",
        "                motion_type=move_robot.intrinsic_proto.skills.MotionSegment.MotionType.ANY,\n",
        "            )\n",
        "        ],\n",
        "        arm_part=world.robot,\n",
        "    ),\n",
        ")\n",
        "\n",
        "move_to_view = bt.Task(\n",
        "    name=\"Move to view\",\n",
        "    action=move_robot(\n",
        "        motion_segments=[\n",
        "            move_robot.intrinsic_proto.skills.MotionSegment(\n",
        "                joint_position=move_robot.intrinsic_proto.icon.JointVec(\n",
        "                    # Known configuration in which the pose estimator has been trained\n",
        "                    joints=[-1.176, -1.934, -1.897, -0.746, 2.199, 0.922]\n",
        "                ),\n",
        "                motion_type=move_robot.intrinsic_proto.skills.MotionSegment.MotionType.ANY,\n",
        "            )\n",
        "        ],\n",
        "        arm_part=world.robot,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "1T64TRNN5G",
      "cell_type": "markdown",
      "source": [
        "Now, for using the return values. Return values are available as a key-value map located in the executive. When creating your application, you will only have to interact with the keys of the values, as the actual values will be computed during execution and available using the key.\n",
        "\n",
        "Every skill you create has a property `result` which can be used to later access the result value. You can also use auto-completion on this, even if the value is not yet available.\n",
        "Instantiate the estimate pose skill and have a look."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "8R1YTA58AE",
      "cell_type": "code",
      "source": [
        "estimate_blocks = bt.Task(\n",
        "    name=\"Detect block\",\n",
        "    action=estimate_pose(\n",
        "        camera=resources.wrist_camera,\n",
        "        perception=resources.perception,\n",
        "        pose_estimator=solution.pose_estimators.building_block_ml_estimator,\n",
        "        min_num_instances=1,\n",
        "        max_num_instances=6,\n",
        "        # Raise object position by 4cm to avoid collision when using as approach pose\n",
        "        object_t_target=data_types.Pose3(translation=[0, 0, -0.04]),\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "T7JZ3M995Z",
      "cell_type": "markdown",
      "source": [
        "Using the following coude, you can print the generated name for the result value of the skill. It will be used during execution to look up the actual pose values."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "ZSKOU36MFA",
      "cell_type": "code",
      "source": [
        "estimate_blocks.result.value_access_path()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "HXEGA5IN6W",
      "cell_type": "markdown",
      "source": [
        "Next, since you want to move over all available blocks use a loop node."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "X9QNV2E7JV",
      "cell_type": "code",
      "source": [
        "loop_node = bt.Loop(name=\"Iterate over Blocks\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "280ZS5RB3K",
      "cell_type": "markdown",
      "source": [
        "Since you want to iterate over the available blocks you can use the loop counter to access a value in the estimate array. \u003cbr\u003e\n",
        "Again, the loop counter is only a string value denoting the key of the index in the key value map. During execution this key will be used to look up the current value of the loop counter. It will only be available inside the loop and is cleared as soon as the loop exits."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "ME5RQAQDAR",
      "cell_type": "code",
      "source": [
        "loop_node.loop_counter"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "KG1IJYM4BG",
      "cell_type": "markdown",
      "source": [
        "Now, put everything together by creating a target for and instance of the `move_robot` skill, which takes the pose from the `estimate_connectors` skill and uses the loop counter as an index in the list."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "YPN3G702P1",
      "cell_type": "code",
      "source": [
        "block_target = move_robot.intrinsic_proto.motion_planning.v1.PoseEquality(\n",
        "    moving_frame=world.picobot_gripper.tool_frame,\n",
        "    target_frame=world.root,\n",
        "    # The following resolves to a blackboard value and is thus computed at execution time\n",
        "    target_frame_offset=estimate_blocks.result.estimates[\n",
        "        loop_node.loop_counter\n",
        "    ].root_t_target,\n",
        ")\n",
        "move_to_block = bt.Task(\n",
        "    name=\"Move to block\",\n",
        "    action=move_robot(\n",
        "        motion_segments=[\n",
        "            move_robot.intrinsic_proto.skills.MotionSegment(\n",
        "                cartesian_pose=block_target,\n",
        "                motion_type=move_robot.intrinsic_proto.skills.MotionSegment.JOINT,\n",
        "            )\n",
        "        ],\n",
        "        arm_part=world.robot,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "V2NBKJKDYO",
      "cell_type": "markdown",
      "source": [
        "Now we can fully configure the loop. We set a condition that limits iteration to the detected objects, such that the loop counter (used as index into the pose estimator result list) does not run out of bounds. The condition is given as a [CEL](https://github.com/google/cel-spec/blob/master/doc/intro.md) expression using the identifiers we inspected before. The condition will be evaluated once before each loop iteration, like in a programming language's while statement."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "TMX0DR3ES9",
      "cell_type": "code",
      "source": [
        "loop_node.set_while_condition(\n",
        "    bt.Blackboard(\n",
        "        f\"size({estimate_blocks.result.estimates.value_access_path()}) \u003e\"\n",
        "        f\" {loop_node.loop_counter}\"\n",
        "    )\n",
        ")\n",
        "loop_node.set_do_child(move_to_block)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "19M6X001C0",
      "cell_type": "markdown",
      "source": [
        "Now we put the created nodes together into a sequence for the tree. We can visualize the created tree."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "QMR4RAK3HM",
      "cell_type": "code",
      "source": [
        "my_bt = bt.BehaviorTree(\n",
        "    root=bt.Sequence([move_home, move_to_view, estimate_blocks, loop_node])\n",
        ")\n",
        "my_bt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "attachments": {},
      "metadata": {
        "colab_type": "text"
      },
      "id": "2MV3UMQLZE",
      "cell_type": "markdown",
      "source": [
        "# Run Behavior Tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "DY80T94YCK",
      "cell_type": "code",
      "source": [
        "executive.run(my_bt)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "colab_type": "text"
      },
      "id": "0JSKO3HIYY",
      "cell_type": "markdown",
      "source": [
        "## Inspect return value of pose estimation skill\n",
        "\n",
        "The `estimate_pose` skill returns a list of estimates for recognized objects. After execution, inspect the result value of the `estimate_blocks` instance of that skill."
      ]
    },
    {
      "metadata": {
        "colab_type": "code"
      },
      "id": "1UNLFG7XCF",
      "cell_type": "code",
      "source": [
        "executive.get_value(estimate_blocks.result)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
